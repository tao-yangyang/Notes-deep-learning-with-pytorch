{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三章主要介绍以下内容：\n",
    "- 将不同种类的真实世界的数据表示成`pytorch`的`tensors`\n",
    "- 处理各种数据类型，包括电子表格，时间序列，文本，图像和医学影像\n",
    "- 从文件中加载数据\n",
    "- 将`data`转换成`tensor`\n",
    "- 根据不同需求调整张量的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习任务中最常见到的可能就是在表格、CSV文件或者数据库中的数据，一般是表格形式呈现。\n",
    "- 首先，表格里面样本之间是独立的，样本在表格中的顺序没有什么意义。\n",
    "- 表格中的列数据类型大部分是不一样的，有些列是整形，有些是字符串，而pytorch的tensor是同质的，一般是浮点型，所以我们要做的是将这些数据都转换成tensor支持的类型\n",
    "网上可以很容易的获取大量的表格数据，[点此获取](https://github.com/caesar0301/awesome-public-datasets.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次我们选用白酒品质数据集进行说明，数据集在`./data/winequality-white.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python`提供给我们几种快速加载CSV文件的方法，如下所示：\n",
    "- `python`的CSV模块\n",
    "- `Numpy`方法\n",
    "- `Pandas`方法*(最省时间最省内存)*\n",
    "\n",
    "鉴于我们之前提过`Numpy`和`tensor`之间可以相互转换，所以我们使用`Numpy`进行过渡生成`tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "        [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "        [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "        ...,\n",
       "        [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "        [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "        [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32),\n",
       " (4898, 12))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "wine_path = \"./data/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1)\n",
    "wineq_numpy, wineq_numpy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上，dtype规定元素数据类型，delimiter规定分隔符，skiprows表示跳过第一行，第一行是列名集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打印出列名集合\n",
    "import csv\n",
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到`numpy`的`ndarray`，然后再转换成`tensor`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  0.4500,  8.8000,  6.0000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  0.4900,  9.5000,  6.0000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  0.4400, 10.1000,  6.0000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  0.4600,  9.4000,  6.0000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  0.3800, 12.8000,  7.0000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  0.3200, 11.8000,  6.0000]]),\n",
       " torch.Size([4898, 12]),\n",
       " 'torch.FloatTensor')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq, wineq.shape, wineq.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**\n",
    "你需要特别注意以下三种数值：\n",
    "1. **`continuous values`**: 这种数值是最常见的，往往就是连续的数值，数值之间可以比较大小，也可以进行数学运算，比如身高体重的值\n",
    "2. **`ordinal values`**: 这种数值是表示顺序的值，数值之间可以比较大小，但是不可以进行数学运算，例如容量大小有三个值small, medium和large,对应于1， 2和 3。可以进行比较大小，但是数学运算没有意义。\n",
    "3. **`categorical values`**: 没有比较大小或者数学运算操作，单纯表示的是分类值，目的是将样本划分进几个类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常情况下，数据最后一列`quality`作为`ground truth`，我们需要将它单独抽出来作为一个新的`tensor`备用:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]        #抽取所有行，抽取除去最后一列的所有列\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]       # 抽取所有行，抽取最后一列\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果遇到需要把`target`当成标签来看的情况，我们可以有以下方法操作：\n",
    "1. 把`target`每一个类别当成一个整数\n",
    "2. 对每一个`target`进行`one-hot`编码\n",
    "\n",
    "关于`one-hot`编码，可以这么理解，已知目前有5类，标号1， 2， 3， 4， 5，我们利用长度为 5 的向量依次表示这5类，重点在于这些向量的元素值不是0就是1\n",
    "\n",
    "类别|one-hot编码\n",
    ":-:|:-:\n",
    "1|1 0 0 0 0\n",
    "2|0 1 0 0 0\n",
    "3|0 0 1 0 0\n",
    "4|0 0 0 1 0\n",
    "5|0 0 0 0 1\n",
    "\n",
    "我们也可以打乱映射顺序，不影响最后结果。这样就可以将类别进行编码，便于计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用scatter_方法实现one-hot编码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们可以使用scatter_方法实现one-hot编码\n",
    "target_onehot = torch.zeros(target.shape[0], 10)      # 有多少类就有多少行，选择多长的向量来表示就可以指定\n",
    "target = target.long()     #这一句是必须的，要把target变成long()\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scatter_方法的参数解释：\n",
    "- The dimension along which the following two arguments are specified \n",
    "- A column tensor indicating the indices of the elements to scatter\n",
    "- A tensor containing the elements to scatter or a single scalar to scatter (1, in this case) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察`unsqueeze()`方法的作用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]), tensor([[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "a_unsqueezed = a.unsqueeze(1)\n",
    "a, a_unsqueezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到表格数据data："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求每一列的均值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 表示均值\n",
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求每一列的方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方差\n",
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7209e-01, -8.1764e-02,  2.1325e-01,  ..., -1.2468e+00,\n",
       "         -3.4914e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7991e-02,  ...,  7.3992e-01,\n",
       "          1.3467e-03, -8.2418e-01],\n",
       "        [ 1.4756e+00,  1.7448e-02,  5.4378e-01,  ...,  4.7502e-01,\n",
       "         -4.3677e-01, -3.3662e-01],\n",
       "        ...,\n",
       "        [-4.2042e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3131e+00,\n",
       "         -2.6152e-01, -9.0544e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0048e+00,\n",
       "         -9.6250e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7502e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize\n",
    "data_normalized = (data - data_mean)/torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们开始处理数据，我们的思路是，先根据`target`将所有样本分成几类，对数据的分布以及规律有个基本的掌握：\n",
    "\n",
    "我们的分类标准是，`target`得分小于等于3的归为`bad_data`；得分（3， 7）之间的归为`mid_data`；得分超过或等于7的归为`good_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们要把target和数字作比较，然后截取符合要求的数据，提供几个torch的方法来实现这个功能：\n",
    "\n",
    "实现目标|方法\n",
    ":-:|:-:\n",
    "a大于等于b|torch.ge(a, b)\n",
    "a小于等于b|torch.le(a, b)\n",
    "a大于b|torch.gt(a, b)\n",
    "a小于b|torch.lt(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[torch.le(target, 3)] \n",
    "mid_data = data[torch.gt(target, 3) & torch.lt(target, 7)] \n",
    "good_data = data[torch.ge(target, 7)]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0) \n",
    "mid_mean = torch.mean(mid_data, dim=0) \n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):    \n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初步观察得，`bad_data`里面`total sulfur dioxide`含量高于其他的样本，那我们可以给定阈值来区分坏酒和好酒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83 \n",
    "total_sulfur_data = data[:,6] \n",
    "# 预测是好酒\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = torch.gt(target, 5)\n",
    "# 事实上好酒\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item() \n",
    "n_predicted = torch.sum(predicted_indexes).item() \n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出来我们这么简单的添加阈值判断好酒坏酒，有2018瓶酒被预测正确\n",
    "\n",
    "虽然这种方法非常简单且结果还算不错，我们心知肚明这肯定不是判断的最好的方法，但这只是开始，等以后接触神经网络和其他算法，我们就可以实现更加准确的预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们了解了表格数据的形式和处理方法，知道了表格数据的每一行都是独立的，没有任何编码信息包含了行的顺序关系。\n",
    "\n",
    "我们这一节主要讲述时间序列的数据，借用上面表格数据很好理解，也就是我们可以新增一个`Year`列，这样我们就可以看到酒的品质`quality`随着时间`year`变化的关系了，但是上面的数据集里面没有。\n",
    "\n",
    "为了更好地了解时间序列，我们重新找了一个数据集：[华盛顿自行车共享系统数据集](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "bike_numpy = np.loadtxt(\"./data/hour-fixed.csv\", dtype=np.float32, delimiter=',', skiprows=1, converters={1: lambda x: float(x[-2:])})\n",
    "# converter的含义是对选中的列进行处理，比如这里对第二列进行截取最后两位，然后强制类型转换\n",
    "bikes = torch.from_numpy(bike_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面我们可以看到数据总共有17520条，每一条17列。\n",
    "\n",
    "观察`CSV`文件可知，`row`是按照每一天来排列，每一天又按照24个小时来排列，所以我们将`bikes`reshape一下， 让其含有三个维度，分别是`（day, hour, 17 columns）`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00,\n",
       "          1.3000e+01, 1.6000e+01],\n",
       "         [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00,\n",
       "          3.2000e+01, 4.0000e+01],\n",
       "         [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00,\n",
       "          2.7000e+01, 3.2000e+01],\n",
       "         ...,\n",
       "         [2.2000e+01, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00,\n",
       "          3.1000e+01, 3.4000e+01],\n",
       "         [2.3000e+01, 1.0000e+00, 1.0000e+00,  ..., 1.1000e+01,\n",
       "          1.7000e+01, 2.8000e+01],\n",
       "         [2.4000e+01, 1.0000e+00, 1.0000e+00,  ..., 1.5000e+01,\n",
       "          2.4000e+01, 3.9000e+01]],\n",
       "\n",
       "        [[2.5000e+01, 2.0000e+00, 1.0000e+00,  ..., 4.0000e+00,\n",
       "          1.3000e+01, 1.7000e+01],\n",
       "         [2.6000e+01, 2.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.6000e+01, 1.7000e+01],\n",
       "         [2.7000e+01, 2.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          8.0000e+00, 9.0000e+00],\n",
       "         ...,\n",
       "         [4.5000e+01, 2.0000e+00, 1.0000e+00,  ..., 1.1000e+01,\n",
       "          2.0000e+01, 3.1000e+01],\n",
       "         [4.6000e+01, 2.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          9.0000e+00, 9.0000e+00],\n",
       "         [4.7000e+01, 2.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          8.0000e+00, 8.0000e+00]],\n",
       "\n",
       "        [[4.8000e+01, 3.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          5.0000e+00, 5.0000e+00],\n",
       "         [4.9000e+01, 3.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          2.0000e+00, 2.0000e+00],\n",
       "         [4.9000e+01, 3.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          2.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [6.7000e+01, 3.0000e+00, 1.0000e+00,  ..., 3.0000e+00,\n",
       "          4.9000e+01, 5.2000e+01],\n",
       "         [6.8000e+01, 3.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          2.0000e+01, 2.0000e+01],\n",
       "         [6.9000e+01, 3.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.1000e+01, 1.2000e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.7308e+04, 2.9000e+01, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          2.5000e+01, 2.6000e+01],\n",
       "         [1.7309e+04, 2.9000e+01, 1.0000e+00,  ..., 6.0000e+00,\n",
       "          3.1000e+01, 3.7000e+01],\n",
       "         [1.7310e+04, 2.9000e+01, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.8000e+01, 1.9000e+01],\n",
       "         ...,\n",
       "         [1.7329e+04, 2.9000e+01, 1.0000e+00,  ..., 4.0000e+00,\n",
       "          5.6000e+01, 6.0000e+01],\n",
       "         [1.7330e+04, 2.9000e+01, 1.0000e+00,  ..., 3.0000e+00,\n",
       "          5.1000e+01, 5.4000e+01],\n",
       "         [1.7331e+04, 2.9000e+01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          3.2000e+01, 3.2000e+01]],\n",
       "\n",
       "        [[1.7332e+04, 3.0000e+01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          4.1000e+01, 4.1000e+01],\n",
       "         [1.7333e+04, 3.0000e+01, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          2.7000e+01, 2.8000e+01],\n",
       "         [1.7334e+04, 3.0000e+01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          1.9000e+01, 1.9000e+01],\n",
       "         ...,\n",
       "         [1.7353e+04, 3.0000e+01, 1.0000e+00,  ..., 5.0000e+00,\n",
       "          4.2000e+01, 4.7000e+01],\n",
       "         [1.7354e+04, 3.0000e+01, 1.0000e+00,  ..., 6.0000e+00,\n",
       "          3.0000e+01, 3.6000e+01],\n",
       "         [1.7355e+04, 3.0000e+01, 1.0000e+00,  ..., 1.0000e+01,\n",
       "          3.9000e+01, 4.9000e+01]],\n",
       "\n",
       "        [[1.7356e+04, 3.1000e+01, 1.0000e+00,  ..., 4.0000e+00,\n",
       "          3.0000e+01, 3.4000e+01],\n",
       "         [1.7357e+04, 3.1000e+01, 1.0000e+00,  ..., 6.0000e+00,\n",
       "          1.3000e+01, 1.9000e+01],\n",
       "         [1.7358e+04, 3.1000e+01, 1.0000e+00,  ..., 3.0000e+00,\n",
       "          8.0000e+00, 1.1000e+01],\n",
       "         ...,\n",
       "         [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00,\n",
       "          8.3000e+01, 9.0000e+01],\n",
       "         [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01,\n",
       "          4.8000e+01, 6.1000e+01],\n",
       "         [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01,\n",
       "          3.7000e+01, 4.9000e+01]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])    #返回一个新的tensor\n",
    "daily_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上数据进行一个讲解，我们得到的`daily_bikes`主要结构是第一维表示哪一天， 第二维表示一天之内的24个小时，第三维表示17个特征。\n",
    "\n",
    "我们通过`stride()`可以知道从当前天数到下一天需要跳过408个数据，这好理解，因为一天内24h，一小时17特征，`17*24=408`。\n",
    "\n",
    "从当前小时到下一个小时，需要跳过17个数据，因为一小时17个特征值。从当前特征跳到下一特征只需要移动1。但是我们希望从当前小时跳到下一小时是连续的，只需要移动1。所以我们需要对第二维和第三维进行转置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们考虑一些特定的特征，比如说`weather-situation`，可以看到这是一个分类特征，一共四个类：1表示最好的天气，4表示最差的天气。我们前面说过，如果将其看成是分类标签的话，可以对它进行`one-hot`编码，为了使操作简单，我们只考虑一天之内的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   1,   1,   0,   1,   0,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           3,  13,  16],\n",
       "        [  2,   1,   1,   0,   1,   1,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           8,  32,  40],\n",
       "        [  3,   1,   1,   0,   1,   2,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           5,  27,  32],\n",
       "        [  4,   1,   1,   0,   1,   3,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           3,  10,  13],\n",
       "        [  5,   1,   1,   0,   1,   4,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           0,   1,   1],\n",
       "        [  6,   1,   1,   0,   1,   5,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           0,   1,   1],\n",
       "        [  7,   1,   1,   0,   1,   6,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           2,   0,   2],\n",
       "        [  8,   1,   1,   0,   1,   7,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           1,   2,   3],\n",
       "        [  9,   1,   1,   0,   1,   8,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           1,   7,   8],\n",
       "        [ 10,   1,   1,   0,   1,   9,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "           8,   6,  14],\n",
       "        [ 11,   1,   1,   0,   1,  10,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "          12,  24,  36],\n",
       "        [ 12,   1,   1,   0,   1,  11,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "          26,  30,  56],\n",
       "        [ 13,   1,   1,   0,   1,  12,   0,   6,   0,   1,   0,   0,   0,   0,\n",
       "          29,  55,  84],\n",
       "        [ 14,   1,   1,   0,   1,  13,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          47,  47,  94],\n",
       "        [ 15,   1,   1,   0,   1,  14,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          35,  71, 106],\n",
       "        [ 16,   1,   1,   0,   1,  15,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          40,  70, 110],\n",
       "        [ 17,   1,   1,   0,   1,  16,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          41,  52,  93],\n",
       "        [ 18,   1,   1,   0,   1,  17,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          15,  52,  67],\n",
       "        [ 19,   1,   1,   0,   1,  18,   0,   6,   0,   3,   0,   0,   0,   0,\n",
       "           9,  26,  35],\n",
       "        [ 20,   1,   1,   0,   1,  19,   0,   6,   0,   3,   0,   0,   0,   0,\n",
       "           6,  31,  37],\n",
       "        [ 21,   1,   1,   0,   1,  20,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          11,  25,  36],\n",
       "        [ 22,   1,   1,   0,   1,  21,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "           3,  31,  34],\n",
       "        [ 23,   1,   1,   0,   1,  22,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          11,  17,  28],\n",
       "        [ 24,   1,   1,   0,   1,  23,   0,   6,   0,   2,   0,   0,   0,   0,\n",
       "          15,  24,  39]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long()    #全部转换成长整型\n",
    "first_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot = torch.zeros(first_day.shape[0], 4)      #指定one-hot的维度\n",
    "first_day[:, 9]    #我们想要得到hours和weather的情况，所以只需要取出weather列即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行one-hot编码\n",
    "weather_onehot.scatter_(dim=1, index=first_day[:, 9].unsqueeze(1)-1, value=1.0)\n",
    "#这里相当于对于一个全0的tensor，按照index来逐个进行赋值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将生成的编码与原始数据合并起来，使用`torch.cat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]  #合并完取出第一行打印出来看看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于转置后的`tensor`如何进行`one-hot`编码呢，转置后的`tensor`是`daily_bikes`，`shape`是`(730*17*24)`。我们还是首先创建一个全0的tensor，形状是`(704, 4， 24)`，因为到时候生成的tensor和原tensor合并，所以只改变中间的，其余维度不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#进行one-hot编码\n",
    "daily_weather_onehot.scatter_(dim=1, index=daily_bikes[:,9,:].long().unsqueeze(1)-1, value=1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 21, 24])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#合并两个tensor\n",
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)\n",
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上作`one-hot`编码，是因为我们将`weather`列当成标签，但是我们之前说过也可以直接当成数值来看待，因为数值之间有大小关系，对应于天气好坏的比较，所以我们接下来介绍当成数值如何操作。\n",
    "\n",
    "我们说过，纯数值列我们可以进行归一化，便于模型训练，常见的归一化有以下两种：\n",
    "```\n",
    "1. min_max归一化\n",
    "2. 0-1归一化\n",
    "```\n",
    "\n",
    "我们拿数据集里面的temperature列作说明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max归一化\n",
    "temp = daily_bikes[:, 10, :]\n",
    "temp_min = torch.min(temp)\n",
    "temp_max = torch.max(temp)\n",
    "daily_bikes[:, 10, :] = (daily_bikes[:, 10, :] - temp_min)/(temp.max - temp.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者使用下面的方法，等效："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1归一化\n",
    "temp = daily_bikes[:, 10, :]\n",
    "daily_bikes[:, 10, :] = (daily_bikes[:, 10, :] - torch.mean(temp)) / torch.std(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就是对于time series数据的简单介绍，我们看完之后如果知道时间数据是如何操作的就很不错了，常见的时间序列数据是文本和语音。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Deep learning`给`NLP`领域带来了巨大的改变，循环神经网络`RNN`被应用的很多。\n",
    "\n",
    "早期的NLP工作主要特征是复杂的多级流水线，其中包括编码语言语法的规则，而现在深度学习方法从头开始训练一个端到端的模型，自动学习出数据隐藏的规则。\n",
    "\n",
    "我们这一节要做的是将文本信息转变成神经网络可以识别的数据，选择的语料库来自 [Project Gutenberg](http://www.gutenberg.org/files/1342/1342-0.txt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/jane-austen/1342-0.txt', encoding='utf-8') as f:\n",
    "    # 这里采用utf-8编码\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Pride and Prejudice, by Jane Austen\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\nTitle: Pride and Prejudice\\n\\nAuthor: Jane Austen\\n\\nPosting Date: August 26, 2008 [EBook #1342]\\nRelease Date: June, 1998\\nLast Updated: March 10, 2018\\n\\nLanguage: English\\n\\nCharacter set encoding: UTF-8\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\\n\\n\\n\\n\\nProduced by Anonymous Volunteers\\n\\n\\n\\n\\n\\nPRIDE AND PREJUDICE\\n\\nBy Jane Austen\\n\\n\\n\\nChapter 1\\n\\n\\nIt is a truth universally acknowledged, that a single man in possession\\nof a good fortune, must be in want of a wife.\\n\\nHowever little known the feelings or views of such a man may be on his\\nfirst entering a neighbourhood, this truth is so well fixed in the minds\\nof the surrounding families, that he is considered the right'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先对text进行切分，取出一行行数据\n",
    "lines = text.split('\\n')     #每一行用\\n间隔\n",
    "line = lines[200]   #取出index为200的行\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们对line这一行的单词进行`one-hot`编码，创建一个大小为`(len(line), 128)`,全0的`tensor`，取128是受ASCII的限制："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_tensor = torch.zeros(len(line), 128)    #这里是按照字符来编码，包括标点符号和空格\n",
    "letter_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`letter_tensor`由70行组成，每一行表示一个字符的`one-hot`编码，所以在正确的位置上设置1是关键，设置1的索引和该字符在`ascii`中的`index`有关："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip()作用是自动去除字符串首尾空格字符\n",
    "for i,letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    letter_tensor[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们进行的是符号编码，我们还可以进行单词编码，我们需要做的就是抽取出单个单词，然后进行编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了去除标点符号以及使字母小写，我们创建一个函数`clean_words()`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"!?”“_-'\n",
    "    word_list = input_str.lower().replace('\\n', '').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
       " ['impossible',\n",
       "  'mr',\n",
       "  'bennet',\n",
       "  'impossible',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'acquainted',\n",
       "  'with',\n",
       "  'him'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个句子，我们将单词都提取出来之后，需要给单词添加对应的索引，方便我们做编码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15514, 6925)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = sorted(set(clean_words(text)))\n",
    "word2index_dict = {word:i for (i, word) in enumerate(word_list)}\n",
    "len(word2index_dict), word2index_dict['impossible']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取每个单词索引之后，我们就可以进行`one-hot`编码了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 6925 impossible\n",
      " 1 8832 mr\n",
      " 2 1906 bennet\n",
      " 3 6925 impossible\n",
      " 4 14844 when\n",
      " 5 6769 i\n",
      " 6  714 am\n",
      " 7 9198 not\n",
      " 8  312 acquainted\n",
      " 9 15085 with\n",
      "10 6387 him\n"
     ]
    }
   ],
   "source": [
    "word_tensor = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_tensor[i][word_index] = 1\n",
    "    print('{:2} {:4} {}'.format(i, word_index, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 15514])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上，你就在你的字典空间中将单词进行编码了，但是`one-hot`编码的方法在单词量很大时，编码长度会特别长，接下来我们将学习一个很重要的概念---`text embbeding`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`one-hot`编码存在哪些问题：\n",
    "- 数据量大，根据单词个数来选择`one-hot`编码的位数\n",
    "- 如果遇到新的单词，那么需要所有单词的编码都新增一列，这开销无疑是巨大的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那如何解决以上问题呢？我们知道`one-hot`编码非0即1，并没有使编码很有效，我们可以采取更少的位数，但是每位都赋予一个浮点数，有效利用每一位，这样的话不仅可以使编码位数变短，也能有效表示单词。\n",
    "\n",
    "这一个技术就叫做`embedding`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以很简单的用很少位数表示很多单词，但这样的话就忽略了有些单词之间的联系，我们的目标是使得相近的单词，其编码也相近，其中一个方法是[Word2vec](https://en.wikipedia.org/wiki/Word2vec.).这里我们就不详细展开了，感兴趣的可以自己探索。我们只要知道，存在这种算法，可以让我们得到一些比较不错的`embedding`表示就可以了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CNN`的出现，使得计算机视觉飞速发展，通过使用输入和期望输出的元素对训练一个端到端的网络，那些需要算法构建块的复杂流水线问题变得可以解决了。\n",
    "\n",
    "图像是由一组数据组成，有特定的结构长和宽，每一个像素使用一个数据表示。要想表示图像的颜色，常用的方法是`RGB`方法，每张图片使用三通道组成：红、绿和蓝，每个通道代表某种颜色的强度，用数字表示，这样三个通道叠加就可以表示颜色。\n",
    "\n",
    "如何使用`python`加载图片呢？ 我们从`imageio`模块开始谈起，它能处理不同的数据类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread('./data/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 77,  45,  22],\n",
       "        [ 77,  45,  22],\n",
       "        [ 78,  46,  21],\n",
       "        ...,\n",
       "        [118,  78,  52],\n",
       "        [117,  77,  51],\n",
       "        [116,  76,  51]],\n",
       "\n",
       "       [[ 75,  43,  20],\n",
       "        [ 76,  44,  21],\n",
       "        [ 77,  45,  20],\n",
       "        ...,\n",
       "        [118,  78,  52],\n",
       "        [117,  77,  51],\n",
       "        [116,  76,  50]],\n",
       "\n",
       "       [[ 74,  39,  17],\n",
       "        [ 75,  41,  16],\n",
       "        [ 77,  43,  18],\n",
       "        ...,\n",
       "        [119,  80,  51],\n",
       "        [117,  77,  51],\n",
       "        [116,  76,  50]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[215, 165,  78],\n",
       "        [216, 166,  79],\n",
       "        [217, 167,  80],\n",
       "        ...,\n",
       "        [172, 122,  51],\n",
       "        [174, 124,  53],\n",
       "        [174, 124,  53]],\n",
       "\n",
       "       [[215, 165,  78],\n",
       "        [216, 166,  79],\n",
       "        [217, 167,  80],\n",
       "        ...,\n",
       "        [173, 123,  54],\n",
       "        [174, 124,  55],\n",
       "        [174, 124,  55]],\n",
       "\n",
       "       [[215, 165,  78],\n",
       "        [216, 166,  79],\n",
       "        [217, 167,  80],\n",
       "        ...,\n",
       "        [159, 108,  42],\n",
       "        [158, 107,  41],\n",
       "        [158, 107,  41]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上代码，我们使用`imageio`模块加载了一张图片，根据图片`shape`知道，图像使用了`RGB`来表示彩色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意`pytorch`要求图像`tensor`维度必须是`C*H*W`的形式，分别是`(channels, height, width)`,上面`img_arr`显示的是`(W*H*C)`,所以我们要进行转置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = torch.transpose(img, 0, 2)     #对tensor进行转置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**\n",
    "这里提一下，不同的框架使用不同的照片表示形式，tensorflow使用`(H*W*C)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里为止，我们已经表示了一张图像，真正实验时，我们输入一个`batch`的数据，也就是输入一个维度为`(N*C*H*W)`的`tensor`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch = torch.zeros(100, 3, 256, 256, dtype=torch.uint8)  #创建一个batch，每张图像高度256pixels, 宽度256pixels，RGB三通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以从目录中加载图片存在`batch`中了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [3, 256, 256].  Tensor sizes: [4, 256, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1f8f75a6eaab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#print(img_arr.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#print(img_arr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (3) must match the existing size (4) at non-singleton dimension 0.  Target sizes: [3, 256, 256].  Tensor sizes: [4, 256, 256]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = './data/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[1] == '.png']\n",
    "\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    filename = os.path.join(data_dir, filename)\n",
    "    img_arr = imageio.imread(filename)\n",
    "    #print(img_arr.shape)\n",
    "    #print(img_arr)\n",
    "    batch[i] = torch.transpose(torch.from_numpy(img_arr), 0, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们发现一个问题，原图像每个颜色使用了四个通道，最后一个通道始终是255，所以我们就将`batch`大小改动一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch = torch.zeros(100, 4, 256, 256, dtype=torch.uint8)  #创建一个batch，每张图像高度256pixels, 宽度256pixels\n",
    "\n",
    "import os\n",
    "data_dir = './data/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[1] == '.png']\n",
    "\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    filename = os.path.join(data_dir, filename)\n",
    "    img_arr = imageio.imread(filename)\n",
    "    #print(img_arr.shape)\n",
    "    #print(img_arr)\n",
    "    batch[i] = torch.transpose(torch.from_numpy(img_arr), 0, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[156, 174, 127,  ..., 116, 129, 129],\n",
       "          [152, 134, 156,  ..., 130, 130, 123],\n",
       "          [124, 165, 107,  ..., 129, 123, 118],\n",
       "          ...,\n",
       "          [150, 120, 131,  ..., 127, 115, 113],\n",
       "          [149, 136, 143,  ..., 118, 121, 121],\n",
       "          [158, 138, 164,  ..., 112, 114, 120]],\n",
       "\n",
       "         [[139, 160, 113,  ...,  99, 111, 111],\n",
       "          [135, 119, 140,  ..., 110, 111, 104],\n",
       "          [109, 149,  90,  ..., 111, 106, 102],\n",
       "          ...,\n",
       "          [135, 105, 118,  ..., 117, 106, 103],\n",
       "          [135, 122, 129,  ..., 108, 112, 110],\n",
       "          [147, 124, 152,  ..., 103, 105, 111]],\n",
       "\n",
       "         [[129, 155, 104,  ...,  93, 108, 107],\n",
       "          [123, 110, 132,  ..., 108, 108,  98],\n",
       "          [ 98, 137,  80,  ..., 105,  98,  95],\n",
       "          ...,\n",
       "          [131, 102, 112,  ..., 125, 110, 108],\n",
       "          [132, 119, 125,  ..., 115, 117, 115],\n",
       "          [145, 121, 146,  ..., 108, 110, 116]],\n",
       "\n",
       "         [[255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]]],\n",
       "\n",
       "\n",
       "        [[[202, 199, 198,  ...,  93,  75,  85],\n",
       "          [193, 192, 193,  ...,  82,  68, 103],\n",
       "          [190, 189, 188,  ...,  76, 101,  90],\n",
       "          ...,\n",
       "          [ 13,  14,  12,  ...,  36,  36,  36],\n",
       "          [ 13,  14,  12,  ...,  36,  36,  37],\n",
       "          [ 12,  14,  12,  ...,  36,  37,  38]],\n",
       "\n",
       "         [[151, 151, 152,  ...,  57,  33,  40],\n",
       "          [139, 140, 143,  ...,  45,  26,  58],\n",
       "          [133, 134, 134,  ...,  39,  59,  45],\n",
       "          ...,\n",
       "          [  9,  11,  11,  ...,  26,  26,  26],\n",
       "          [  9,  11,  11,  ...,  26,  26,  27],\n",
       "          [  8,  11,  11,  ...,  26,  27,  28]],\n",
       "\n",
       "         [[ 68,  67,  67,  ...,  31,  11,  19],\n",
       "          [ 53,  54,  56,  ...,  19,   2,  37],\n",
       "          [ 44,  44,  44,  ...,  12,  35,  22],\n",
       "          ...,\n",
       "          [  6,   6,   6,  ...,  17,  17,  17],\n",
       "          [  6,   6,   6,  ...,  17,  17,  18],\n",
       "          [  5,   6,   6,  ...,  17,  18,  19]],\n",
       "\n",
       "         [[255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]]],\n",
       "\n",
       "\n",
       "        [[[238, 238, 238,  ..., 214, 214, 214],\n",
       "          [238, 238, 238,  ..., 213, 213, 213],\n",
       "          [238, 238, 238,  ..., 212, 212, 212],\n",
       "          ...,\n",
       "          [214, 214, 214,  ..., 187, 186, 186],\n",
       "          [215, 215, 215,  ..., 190, 190, 190],\n",
       "          [215, 215, 215,  ..., 193, 192, 192]],\n",
       "\n",
       "         [[195, 195, 195,  ..., 128, 128, 128],\n",
       "          [195, 195, 195,  ..., 127, 127, 127],\n",
       "          [195, 195, 195,  ..., 126, 126, 126],\n",
       "          ...,\n",
       "          [173, 173, 173,  ..., 100,  99,  99],\n",
       "          [175, 175, 175,  ..., 103, 103, 103],\n",
       "          [175, 175, 175,  ..., 106, 105, 105]],\n",
       "\n",
       "         [[137, 137, 137,  ...,  79,  79,  79],\n",
       "          [137, 137, 137,  ...,  78,  78,  78],\n",
       "          [137, 137, 137,  ...,  77,  77,  77],\n",
       "          ...,\n",
       "          [125, 125, 125,  ...,  64,  64,  65],\n",
       "          [126, 126, 126,  ...,  68,  69,  69],\n",
       "          [126, 126, 126,  ...,  72,  71,  72]],\n",
       "\n",
       "         [[255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          ...,\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255],\n",
       "          [255, 255, 255,  ..., 255, 255, 255]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]]],\n",
       "\n",
       "\n",
       "        [[[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]]],\n",
       "\n",
       "\n",
       "        [[[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "         [[  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常情况下，我们将图片的各个像素值归一化到（0,1）或者（-1,1）之间，这很好实现，直接让batch每一个值/255就可以了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6118, 0.6824, 0.4980,  ..., 0.4549, 0.5059, 0.5059],\n",
       "          [0.5961, 0.5255, 0.6118,  ..., 0.5098, 0.5098, 0.4824],\n",
       "          [0.4863, 0.6471, 0.4196,  ..., 0.5059, 0.4824, 0.4627],\n",
       "          ...,\n",
       "          [0.5882, 0.4706, 0.5137,  ..., 0.4980, 0.4510, 0.4431],\n",
       "          [0.5843, 0.5333, 0.5608,  ..., 0.4627, 0.4745, 0.4745],\n",
       "          [0.6196, 0.5412, 0.6431,  ..., 0.4392, 0.4471, 0.4706]],\n",
       "\n",
       "         [[0.5451, 0.6275, 0.4431,  ..., 0.3882, 0.4353, 0.4353],\n",
       "          [0.5294, 0.4667, 0.5490,  ..., 0.4314, 0.4353, 0.4078],\n",
       "          [0.4275, 0.5843, 0.3529,  ..., 0.4353, 0.4157, 0.4000],\n",
       "          ...,\n",
       "          [0.5294, 0.4118, 0.4627,  ..., 0.4588, 0.4157, 0.4039],\n",
       "          [0.5294, 0.4784, 0.5059,  ..., 0.4235, 0.4392, 0.4314],\n",
       "          [0.5765, 0.4863, 0.5961,  ..., 0.4039, 0.4118, 0.4353]],\n",
       "\n",
       "         [[0.5059, 0.6078, 0.4078,  ..., 0.3647, 0.4235, 0.4196],\n",
       "          [0.4824, 0.4314, 0.5176,  ..., 0.4235, 0.4235, 0.3843],\n",
       "          [0.3843, 0.5373, 0.3137,  ..., 0.4118, 0.3843, 0.3725],\n",
       "          ...,\n",
       "          [0.5137, 0.4000, 0.4392,  ..., 0.4902, 0.4314, 0.4235],\n",
       "          [0.5176, 0.4667, 0.4902,  ..., 0.4510, 0.4588, 0.4510],\n",
       "          [0.5686, 0.4745, 0.5725,  ..., 0.4235, 0.4314, 0.4549]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.7922, 0.7804, 0.7765,  ..., 0.3647, 0.2941, 0.3333],\n",
       "          [0.7569, 0.7529, 0.7569,  ..., 0.3216, 0.2667, 0.4039],\n",
       "          [0.7451, 0.7412, 0.7373,  ..., 0.2980, 0.3961, 0.3529],\n",
       "          ...,\n",
       "          [0.0510, 0.0549, 0.0471,  ..., 0.1412, 0.1412, 0.1412],\n",
       "          [0.0510, 0.0549, 0.0471,  ..., 0.1412, 0.1412, 0.1451],\n",
       "          [0.0471, 0.0549, 0.0471,  ..., 0.1412, 0.1451, 0.1490]],\n",
       "\n",
       "         [[0.5922, 0.5922, 0.5961,  ..., 0.2235, 0.1294, 0.1569],\n",
       "          [0.5451, 0.5490, 0.5608,  ..., 0.1765, 0.1020, 0.2275],\n",
       "          [0.5216, 0.5255, 0.5255,  ..., 0.1529, 0.2314, 0.1765],\n",
       "          ...,\n",
       "          [0.0353, 0.0431, 0.0431,  ..., 0.1020, 0.1020, 0.1020],\n",
       "          [0.0353, 0.0431, 0.0431,  ..., 0.1020, 0.1020, 0.1059],\n",
       "          [0.0314, 0.0431, 0.0431,  ..., 0.1020, 0.1059, 0.1098]],\n",
       "\n",
       "         [[0.2667, 0.2627, 0.2627,  ..., 0.1216, 0.0431, 0.0745],\n",
       "          [0.2078, 0.2118, 0.2196,  ..., 0.0745, 0.0078, 0.1451],\n",
       "          [0.1725, 0.1725, 0.1725,  ..., 0.0471, 0.1373, 0.0863],\n",
       "          ...,\n",
       "          [0.0235, 0.0235, 0.0235,  ..., 0.0667, 0.0667, 0.0667],\n",
       "          [0.0235, 0.0235, 0.0235,  ..., 0.0667, 0.0667, 0.0706],\n",
       "          [0.0196, 0.0235, 0.0235,  ..., 0.0667, 0.0706, 0.0745]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.9333, 0.9333, 0.9333,  ..., 0.8392, 0.8392, 0.8392],\n",
       "          [0.9333, 0.9333, 0.9333,  ..., 0.8353, 0.8353, 0.8353],\n",
       "          [0.9333, 0.9333, 0.9333,  ..., 0.8314, 0.8314, 0.8314],\n",
       "          ...,\n",
       "          [0.8392, 0.8392, 0.8392,  ..., 0.7333, 0.7294, 0.7294],\n",
       "          [0.8431, 0.8431, 0.8431,  ..., 0.7451, 0.7451, 0.7451],\n",
       "          [0.8431, 0.8431, 0.8431,  ..., 0.7569, 0.7529, 0.7529]],\n",
       "\n",
       "         [[0.7647, 0.7647, 0.7647,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.7647, 0.7647, 0.7647,  ..., 0.4980, 0.4980, 0.4980],\n",
       "          [0.7647, 0.7647, 0.7647,  ..., 0.4941, 0.4941, 0.4941],\n",
       "          ...,\n",
       "          [0.6784, 0.6784, 0.6784,  ..., 0.3922, 0.3882, 0.3882],\n",
       "          [0.6863, 0.6863, 0.6863,  ..., 0.4039, 0.4039, 0.4039],\n",
       "          [0.6863, 0.6863, 0.6863,  ..., 0.4157, 0.4118, 0.4118]],\n",
       "\n",
       "         [[0.5373, 0.5373, 0.5373,  ..., 0.3098, 0.3098, 0.3098],\n",
       "          [0.5373, 0.5373, 0.5373,  ..., 0.3059, 0.3059, 0.3059],\n",
       "          [0.5373, 0.5373, 0.5373,  ..., 0.3020, 0.3020, 0.3020],\n",
       "          ...,\n",
       "          [0.4902, 0.4902, 0.4902,  ..., 0.2510, 0.2510, 0.2549],\n",
       "          [0.4941, 0.4941, 0.4941,  ..., 0.2667, 0.2706, 0.2706],\n",
       "          [0.4941, 0.4941, 0.4941,  ..., 0.2824, 0.2784, 0.2824]],\n",
       "\n",
       "         [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一种方法就是使用均值和标准差来归一化数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])     # 均值是每一张图所有值的均值\n",
    "    std = torch.std(batch[:, c])    # std是一张图所有值的std\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍完图像，我们介绍一种特殊的图像，CT扫描图像，它特殊在是由很多部分的扫描组成的，不像图像是一整个图像的内容，CT是部分拼成一个整体，所以我们表示这一类数据时，往往是将几个2D图像拼接成3D图像："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以对于这一类数据，比普通2D图像多了一维，所以它的batch形状为`(N*C*D*H*W)`,其中D就是多出来的维度："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用`imggeio`模块下的`volread`函数加载样例：\n",
    "`DICOM`表示`Digital Imaging Communication and Storage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 65/99  (65.799/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "dir_path = \"./data/volumetric-dicom/2-LUNG 3.0  B70f-04083\"\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的例子中，维度和`pytorch`要求的维度不同，需要进行转置，但是因为缺乏`channel`信息，所以我们要使用`unsqueeze`为`channel`维度空出空间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.transpose(vol, 0, 2)\n",
    "vol = torch.unsqueeze(vol, 0)   # 表示在第0维增加一个维度值为1的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 512, 99])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们就可以将很多样本集合起来，构成一个5维的batch，进行训练。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
